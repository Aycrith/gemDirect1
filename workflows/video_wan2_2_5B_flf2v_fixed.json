{
  "id": "wan2-5b-flf2v-fixed",
  "revision": 2,
  "last_node_id": 16,
  "last_link_id": 14,
  "_meta": {
    "title": "WAN 2.2 5B First-Last-Frame to Video (Fixed)",
    "description": "Native dual-keyframe video generation using Wan22FirstLastFrameToVideoLatentTiledVAE custom node. Optimized for 24GB VRAM with 5B model and tiled VAE encoding.",
    "author": "gemDirect",
    "version": "2.0.0"
  },
  "nodes": {
    "1": {
      "inputs": {
        "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "type": "wan",
        "device": "default"
      },
      "class_type": "CLIPLoader",
      "_meta": {
        "title": "Load CLIP"
      }
    },
    "2": {
      "inputs": {
        "vae_name": "wan2.2_vae.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "3": {
      "inputs": {
        "unet_name": "wan2.2_ti2v_5B_fp16.safetensors",
        "weight_dtype": "default"
      },
      "class_type": "UNETLoader",
      "_meta": {
        "title": "Load Diffusion Model (5B)"
      }
    },
    "4": {
      "inputs": {
        "shift": 8,
        "model": [
          "3",
          0
        ]
      },
      "class_type": "ModelSamplingSD3",
      "_meta": {
        "title": "ModelSamplingSD3"
      }
    },
    "5": {
      "inputs": {
        "text": "A cinematic video scene with smooth motion and natural transitions between the start and end frames.",
        "clip": [
          "1",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "6": {
      "inputs": {
        "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走, static, no motion, frozen, split screen, multiple panels, comic panels, manga style, grid layout",
        "clip": [
          "1",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Negative Prompt)"
      }
    },
    "10": {
      "inputs": {
        "image": "start_keyframe.png"
      },
      "class_type": "LoadImage",
      "_meta": {
        "title": "Load Start Image"
      }
    },
    "11": {
      "inputs": {
        "image": "end_keyframe.png"
      },
      "class_type": "LoadImage",
      "_meta": {
        "title": "Load End Image"
      }
    },
    "12": {
      "inputs": {
        "width": 832,
        "height": 480,
        "length": 81,
        "batch_size": 1,
        "tile_size": 512,
        "overlap": 64,
        "temporal_size": 64,
        "temporal_overlap": 8,
        "vae": [
          "2",
          0
        ],
        "start_image": [
          "10",
          0
        ],
        "end_image": [
          "11",
          0
        ]
      },
      "class_type": "Wan22FirstLastFrameToVideoLatentTiledVAE",
      "_meta": {
        "title": "WAN 2.2 First-Last Frame to Video Latent (Tiled VAE)"
      }
    },
    "13": {
      "inputs": {
        "seed": 123456789,
        "steps": 20,
        "cfg": 5,
        "sampler_name": "uni_pc",
        "scheduler": "simple",
        "denoise": 1,
        "model": [
          "4",
          0
        ],
        "positive": [
          "5",
          0
        ],
        "negative": [
          "6",
          0
        ],
        "latent_image": [
          "12",
          0
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "14": {
      "inputs": {
        "samples": [
          "13",
          0
        ],
        "vae": [
          "2",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "15": {
      "inputs": {
        "fps": 16,
        "images": [
          "14",
          0
        ]
      },
      "class_type": "CreateVideo",
      "_meta": {
        "title": "Create Video"
      }
    },
    "16": {
      "inputs": {
        "filename_prefix": "video/wan2_flf2v",
        "format": "auto",
        "codec": "auto",
        "video": [
          "15",
          0
        ]
      },
      "class_type": "SaveVideo",
      "_meta": {
        "title": "Save Video"
      }
    }
  },
  "links": [
    [1, "1", 0, "5", 0, "CLIP"],
    [2, "1", 0, "6", 0, "CLIP"],
    [3, "3", 0, "4", 0, "MODEL"],
    [4, "2", 0, "12", 0, "VAE"],
    [5, "10", 0, "12", 1, "IMAGE"],
    [6, "11", 0, "12", 2, "IMAGE"],
    [7, "4", 0, "13", 0, "MODEL"],
    [8, "5", 0, "13", 1, "CONDITIONING"],
    [9, "6", 0, "13", 2, "CONDITIONING"],
    [10, "12", 0, "13", 3, "LATENT"],
    [11, "13", 0, "14", 0, "LATENT"],
    [12, "2", 0, "14", 1, "VAE"],
    [13, "14", 0, "15", 0, "IMAGE"],
    [14, "15", 0, "16", 0, "VIDEO"]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "gemDirect": {
      "workflowType": "flf2v",
      "modelSize": "5B",
      "requiredNodes": ["Wan22FirstLastFrameToVideoLatentTiledVAE"],
      "customNodeRepo": "https://github.com/stduhpf/ComfyUI--Wan22FirstLastFrameToVideoLatent",
      "vramRequirement": "~10-12GB",
      "resolution": "832x480 (16:9)",
      "notes": "Uses Wan22FirstLastFrameToVideoLatentTiledVAE for VRAM-efficient dual-keyframe interpolation. CLIP encoders connect directly to KSampler. No FFmpeg required."
    }
  },
  "version": 0.4
}
