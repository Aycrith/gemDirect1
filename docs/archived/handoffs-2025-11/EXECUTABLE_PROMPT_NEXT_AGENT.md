# ðŸŽ¯ EXECUTABLE PROMPT FOR NEXT AGENT - FULL FEATURE BRANCH COMPLETION

**Purpose**: This is a complete, self-contained instruction set for an AI Coding Agent to execute in an isolated, new session to complete all remaining work on the gemDirect1 feature branch.

**How to Use This Prompt**: Pass this entire document to a new AI Coding Agent with the context that they should execute it autonomously while reporting progress.

---

## YOUR MISSION

You are being assigned to complete the **React browser testing implementation and feature branch finalization** for a cinematic story generator application (gemDirect1). This is the 7th session of development, and your work builds on 6 previous sessions of implementation.

**Your job**: 
1. Review all handoff documentation
2. Fix remaining test gaps
3. Update all project meta-documents
4. Ensure production readiness
5. Deliver a complete, tested, documented feature branch

**Time Expected**: 4-8 hours  
**Complexity**: Medium (mostly mechanical work, some debugging)  
**Autonomy Level**: High (make decisions as needed, ask for clarification only if blocked)

---

## STARTING CHECKLIST

Before you start, verify you have:

- âœ… Access to the workspace: `c:\Dev\gemDirect1`
- âœ… Ability to read files, run terminal commands, and edit code
- âœ… Understanding of React, TypeScript, and Playwright testing
- âœ… Access to the following key documents:
  - `COMPREHENSIVE_AGENT_HANDOFF_NEXTPHASE.md` (SECTION 1-5 required reading)
  - `README.md`
  - `REACT_BROWSER_TESTING_PROGRESS_REPORT.md`

**Gate**: Read `COMPREHENSIVE_AGENT_HANDOFF_NEXTPHASE.md` FIRST. This document assumes you've read it.

---

## YOUR EXPLICIT INSTRUCTIONS

### PHASE 1: CONTEXT & PLANNING (First 40 minutes)

**Goal**: Understand what's been built, what's left, and create a detailed plan.

**INSTRUCTION 1.1: Read Core Documentation**

Read these files in this exact order (use `read_file` tool):
1. `COMPREHENSIVE_AGENT_HANDOFF_NEXTPHASE.md` - **ALL of it** (this is your master guide)
2. `README.md` - **Top 150 lines** (understand project)
3. `.github/copilot-instructions.md` - **ALL** (understand architecture)
4. `REACT_BROWSER_TESTING_PROGRESS_REPORT.md` - **ALL** (understand current test status)

**Checkpoint**: You must be able to explain:
- Why we use Mistral LLM instead of mocking Gemini
- What the 6 testing phases are and current status (27/40 passing)
- What the 3 main gaps are and why they exist
- Where all key files are located

**If you cannot explain these**, re-read until you can. Don't proceed until this is clear.

**INSTRUCTION 1.2: Current State Snapshot**

Run these commands and record the output:
```powershell
# Check test status
npx playwright test tests/e2e/ --reporter=list 2>&1 | Select-String -Pattern "passed|failed|skipped|Running"

# Check build status
npm run build 2>&1 | Select-String -Pattern "error|Error|ERROR|built successfully"

# Check for broken imports
npm ls 2>&1 | Select-String -Pattern "ERR!|missing|unmet"
```

**Record**:
- Current test count (should be ~40 total, 27 passing)
- Build status (should succeed with no errors)
- Any dependency issues

**INSTRUCTION 1.3: Create Your Plan**

Based on reading the handoff document, create a prioritized task list:

**Format**:
```
# MY EXECUTION PLAN

## Time Budget
- Reading & Planning: X minutes (done)
- Fix Phase 3 UI selectors: 30-45 minutes
- Update meta-documents: 60-90 minutes
- [Optional] Investigate CORS: 45-60 minutes
- [Optional] Extend tests: 120-180 minutes
- Final validation: 20-30 minutes

**Total time needed**: X hours

## Tasks (In Order)
1. [ ] Run current test suite, record baseline
2. [ ] Inspect DOM for Phase 3 selectors (need: scene cards, shot cards, camera info)
3. [ ] Update tests/e2e/scene-generation.spec.ts with real selectors
4. [ ] Update tests/e2e/timeline-editing.spec.ts with real selectors
5. [ ] Re-run Phase 3 tests, verify passing
6. [ ] Update README.md (add React testing section, remove broken references)
7. [ ] Update .github/copilot-instructions.md (add local LLM testing approach)
8. [ ] Update WORKFLOW_ARCHITECTURE_REFERENCE.md (verify WAN references, not SVD)
9. [ ] Create REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md (complete developer reference)
10. [ ] [OPTIONAL] Investigate CORS configuration
11. [ ] [OPTIONAL] Implement full E2E pipeline test
12. [ ] Final validation: run full suite, verify metrics, check documentation

## Success Criteria
- âœ… Test count same or higher (â‰¥27/40 passing = 67.5%)
- âœ… All documentation updated and consistent
- âœ… No broken file references
- âœ… Build completes successfully
```

**Submit your plan** to the user before proceeding.

---

### PHASE 2: BASELINE & INSPECTION (Next 30 minutes)

**Goal**: Get current test results and understand what needs fixing.

**INSTRUCTION 2.1: Run Full Test Suite**

```powershell
# Navigate to project
cd c:\Dev\gemDirect1

# Make sure dev server is running (in background if not)
# npm run dev &

# Run all tests with detailed output
npx playwright test tests/e2e/ --reporter=list
```

**Record**:
- Total test count
- Passing count
- Failing count  
- Skipped count
- Any error messages

**Expected**: ~40 tests total, ~27 passing, ~10 skipped, ~3 failing

**Checkpoint**: If counts differ significantly from expected, investigate why before proceeding.

**INSTRUCTION 2.2: Identify Phase 3 Skipped Tests**

Run only Phase 3 tests to see what needs fixing:
```powershell
npx playwright test tests/e2e/scene-generation.spec.ts tests/e2e/timeline-editing.spec.ts --reporter=list
```

**Check**:
- Are tests skipped? (Look for `SKIP` in output)
- What are the skip reasons in the test file comments?
- What selectors are mentioned as "needs verification"?

**Read** both test files to find:
- `test.skip()` calls
- Comments explaining why tests are skipped
- Placeholder selector strings (e.g., `.scene-card-NEEDS-UPDATE`)

---

### PHASE 3: FIX PHASE 3 UI SELECTORS (30-45 minutes)

**Goal**: Update skipped Phase 3 tests with real DOM selectors.

**INSTRUCTION 3.1: Inspect DOM for Scene Cards**

1. Start the app:
   ```powershell
   npm run dev
   ```

2. Open browser to http://localhost:3000

3. Navigate to Director Mode:
   - Story Bible â†’ Generate Story (or use mock data)
   - Switch to Director Mode (button should appear after generation)

4. Open DevTools (F12) and inspect:
   - **Scene navigator**: What class/selector? (likely `.scene-card`, `[data-testid="scene-card"]`)
   - **Timeline section**: Where are shot cards? (likely `.shot-card`, `[data-scene-id="..."]`)
   - **Camera info**: What element displays it? (inspect sidebar or panel)

5. Record the actual selectors:
   ```
   Scene cards: [actual selector]
   Shot cards: [actual selector]
   Camera info element: [actual selector]
   ```

**INSTRUCTION 3.2: Update test/e2e/scene-generation.spec.ts**

Use `read_file` to view current file:
```powershell
# Read first 150 lines to see structure
read_file -filePath "c:\Dev\gemDirect1\tests\e2e\scene-generation.spec.ts" -limit 150
```

Find lines with:
- `test.skip('scene navigator display')`
- Comments like `// SKIP REASON: Selector ...`

Update each skipped test:
1. Replace placeholder selector with real selector from your DOM inspection
2. Remove `.skip()` from test name (or keep if you want to keep it skipped)
3. Update comments to explain why selector was chosen

**Example**:
```typescript
// BEFORE:
test.skip('scene navigator should display all scenes', async ({ page }) => {
  // SKIP REASON: Selector '.scene-card-NEEDS-UPDATE' needs verification
  const sceneCards = await page.locator('.scene-card-NEEDS-UPDATE').all();
});

// AFTER:
test('scene navigator should display all scenes', async ({ page }) => {
  // Verified selector against actual DOM on 2025-11-19
  // Scene cards rendered with class 'scene-card' in .scenes-navigator
  const sceneCards = await page.locator('.scene-card').all();
  expect(sceneCards.length).toBeGreaterThan(0);
});
```

**INSTRUCTION 3.3: Update tests/e2e/timeline-editing.spec.ts**

Repeat the same process for timeline tests:
1. Find all `test.skip()` calls
2. Replace placeholder selectors with real ones
3. Remove `.skip()` or update reason
4. Add comment explaining selector choice

**INSTRUCTION 3.4: Re-run Phase 3 Tests**

```powershell
npx playwright test tests/e2e/scene-generation.spec.ts tests/e2e/timeline-editing.spec.ts --reporter=list
```

**Check**:
- Do tests now pass? (Great!)
- Do tests fail with selector errors? (Update selector, re-run)
- Do tests fail with assertion errors? (Fix test logic, re-run)
- Do tests still skip? (Update comment explaining why)

**Goal**: Move tests from "skipped" to "passing" or "failing with known reason"

**Report**: Submit screenshot or paste test output showing new results.

---

### PHASE 4: UPDATE META-DOCUMENTS (60-90 minutes)

**Goal**: Update all project documentation to reflect current state.

**INSTRUCTION 4.1: Update README.md**

Current `README.md` needs updates. Use `replace_string_in_file` to make these changes:

1. **Add React Testing Section** (find "## Run Locally" section, add after):
```markdown
## React Browser Testing

### Test Coverage (40 tests total)
- Phase 1 (App Loading): 4/4 passing âœ…
- Phase 2 (Story Generation): 3/5 passing (60%)
- Phase 3 (Scene/Timeline): 2/8 passing (25%) - UI selectors need verification
- Phase 4 (ComfyUI Integration): 4/5 passing (80%)
- Phase 5 (Data Persistence): 6/7 passing (86%)
- Phase 6 (Error Handling): 8/8 passing (100%) âœ…

**Total Coverage**: 27/40 tests passing (67.5%)

### Running Tests
\`\`\`bash
npm run dev                              # Start dev server (port 3000)
npx playwright test                      # Run all E2E tests
npx playwright test --reporter=html      # Generate HTML report
npx playwright test --debug              # Debug mode
\`\`\`

### Known Limitations
- Phase 2: 2 tests skipped due to CORS (LM Studio doesn't return CORS headers for browser fetch)
- Phase 3: 6 tests skipped pending UI selector verification (inspect DOM with `npm run dev`)
- Phase 4: 1 test skipped pending ComfyUI settings modal verification

See `REACT_BROWSER_TESTING_PROGRESS_REPORT.md` for detailed test breakdown.
```

2. **Remove Broken References** - Search for and remove:
   - `contexts/PipelineContext.tsx` (doesn't exist)
   - `components/VisualBiblePanel.tsx` (doesn't exist)
   - Any SVD-specific instructions (should be WAN only)

3. **Add Testing Configuration** - Add to "### Local LLM (LM Studio) requirements" section:
```markdown
### Playwright Test Environment Variables
The following variables are automatically set by \`playwright.config.ts\`:
\`\`\`powershell
$env:VITE_PLAYWRIGHT_SKIP_WELCOME = 'true'           # Bypass welcome dialog in tests
$env:VITE_LOCAL_STORY_PROVIDER_URL = 'http://192.168.50.192:1234/v1/chat/completions'
$env:VITE_LOCAL_LLM_MODEL = 'mistralai/mistral-7b-instruct-v0.3'
$env:VITE_LOCAL_LLM_REQUEST_FORMAT = 'openai-chat'
$env:VITE_LOCAL_LLM_TEMPERATURE = '0.35'
\`\`\`
These must be set before running Playwright tests.
```

**INSTRUCTION 4.2: Update .github/copilot-instructions.md**

Find "### Testing Strategy" section and add:

```markdown
### Testing Strategy (React Browser E2E)

**Approach**: Real integration testing with local LLM (NOT SDK mocking)
- Use Mistral 7B via LM Studio at http://192.168.50.192:1234
- Set `VITE_PLAYWRIGHT_SKIP_WELCOME=true` to bypass welcome dialog
- Set `VITE_LOCAL_*` environment variables for LLM configuration
- Configure playwright.config.ts webServer with these variables

**Why Not Mock Gemini SDK?**
The Google Generative AI SDK bypasses Playwright route interception:
- SDK makes internal HTTP calls that don't route through page.route()
- Response mocking at fetch level doesn't work for SDK-wrapped requests
- Solution: Use real local services (LM Studio, ComfyUI) in tests instead

**Pattern**: All E2E tests should use real services (with Playwright route interception for mocking specific scenarios)
```

Also add to "## Common Test Failures & Fixes":
```markdown
### "Browser fetch fails to LM Studio" (Phase 2 tests)
**Root cause**: CORS headers missing on LM Studio response
- **Limitation**: Browser fetch blocked, but Node.js fetch works
- **Workaround**: Tests skip this scenario, validate via unit tests instead
- **Future fix**: Configure LM Studio CORS headers or implement reverse proxy
```

**INSTRUCTION 4.3: Update WORKFLOW_ARCHITECTURE_REFERENCE.md**

1. Search the file for any "SVD" references
2. For each SVD reference, verify it should be WAN instead or mark as optional/legacy
3. Update to use consistent WAN workflow names:
   - T2I: `workflows/image_netayume_lumina_t2i.json`
   - I2V: `workflows/video_wan2_2_5B_ti2v.json`

**INSTRUCTION 4.4: Create REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md**

Create a new file at `c:\Dev\gemDirect1\REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md`:

```markdown
# React Browser Testing Developer Guide

## Overview

This guide explains how to develop and extend the Playwright E2E test suite for gemDirect1.

## Test Organization

### File Structure
\`\`\`
tests/
â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ app-loading.spec.ts          # Phase 1: Basic app loading
â”‚   â”œâ”€â”€ story-generation.spec.ts     # Phase 2: Story bible generation
â”‚   â”œâ”€â”€ scene-generation.spec.ts     # Phase 3: Scene breakdown
â”‚   â”œâ”€â”€ timeline-editing.spec.ts     # Phase 3: Timeline editing
â”‚   â”œâ”€â”€ video-generation.spec.ts     # Phase 4: ComfyUI integration
â”‚   â”œâ”€â”€ data-persistence.spec.ts     # Phase 5: IndexedDB persistence
â”‚   â””â”€â”€ error-handling.spec.ts       # Phase 6: Error recovery
â””â”€â”€ fixtures/
    â”œâ”€â”€ mock-data.ts                 # Reusable test data
    â”œâ”€â”€ test-helpers.ts              # DOM interaction utilities
    â””â”€â”€ gemini-mock.ts               # Gemini API response scenarios
\`\`\`

### Phase Breakdown

**Phase 1: App Loading (4 tests)**
- Verifies React app starts without errors
- Checks main UI elements render
- Validates IndexedDB initialization
- Tests mode switching (Quick Generate â†” Director Mode)

**Phase 2: Story Generation (5 tests)**
- Tests story bible form
- Validates story generation via LM Studio
- Tests API error handling
- Checks data persistence after generation
- **Known Limitation**: 2 tests skipped (CORS blocks browser fetch to LLM)

**Phase 3: Scene Generation & Timeline Editing (8 tests)**
- Tests scene navigator display
- Validates scene selection
- Tests timeline editing UI
- Verifies shot card interactions
- **Known Limitation**: 6 tests skipped (UI selectors need verification)

**Phase 4: ComfyUI Integration (5 tests)**
- Tests settings modal access
- Validates workflow configuration
- Tests queue interaction
- Verifies ComfyUI status display
- Checks keyframe persistence

**Phase 5: Data Persistence (7 tests)**
- Tests IndexedDB save/load
- Validates project export/import
- Tests data consistency across sessions
- Verifies workflow state persistence

**Phase 6: Error Handling (8 tests)**
- Tests network error recovery
- Validates invalid data handling
- Tests form validation
- Checks console error monitoring
- Tests race condition prevention

## Test Fixtures & Utilities

### mock-data.ts
Contains reusable test data structures:
- \`mockStoryBible\`: Complete story bible object
- \`mockScene\`: Scene structure with shots
- \`mockTimeline\`: Timeline with shot sequence
- \`mockProjectState\`: Full project state for IndexedDB

Usage:
\`\`\`typescript
import { mockData } from '../fixtures/mock-data';

const storyBible = mockData.storyBible;
const scene = mockData.scene;
\`\`\`

### test-helpers.ts
Common test utilities:
- \`dismissWelcomeDialog()\`: Bypass welcome modal
- \`ensureDirectorMode()\`: Switch to director mode
- \`loadProjectState()\`: Load data into IndexedDB
- \`clearProjectData()\`: Reset IndexedDB

Usage:
\`\`\`typescript
import { dismissWelcomeDialog, loadProjectState } from '../fixtures/test-helpers';

test('scenario', async ({ page }) => {
  await dismissWelcomeDialog(page);
  await loadProjectState(page, mockData.projectWithStory);
});
\`\`\`

### gemini-mock.ts
API response scenarios for testing:
- Success responses
- Rate limit (429) errors
- Network timeouts
- Invalid JSON responses

## Configuration

### playwright.config.ts
Sets up Playwright environment:
- Browser: Chromium
- Dev server URL: http://localhost:3000
- Environment variables: VITE_PLAYWRIGHT_SKIP_WELCOME, VITE_LOCAL_*
- Timeout: 30 seconds per test
- Retry: Failed tests retry once

### .env.local
Local development variables:
- VITE_LOCAL_STORY_PROVIDER_URL: LM Studio endpoint
- VITE_LOCAL_LLM_MODEL: Mistral model name
- VITE_LOCAL_LLM_TEMPERATURE: Generation temperature
- Other VITE_LOCAL_* variables

## Running Tests

### Individual Test
\`\`\`bash
npx playwright test tests/e2e/app-loading.spec.ts
\`\`\`

### Specific Phase
\`\`\`bash
npx playwright test tests/e2e/story-generation.spec.ts --reporter=list
\`\`\`

### All Tests
\`\`\`bash
npx playwright test
\`\`\`

### Debug Mode
\`\`\`bash
npx playwright test --debug
\`\`\`

### HTML Report
\`\`\`bash
npx playwright test --reporter=html
# Open: playwright-report/index.html
\`\`\`

## Adding a New Test

### Template
\`\`\`typescript
import { test, expect } from '@playwright/test';
import { dismissWelcomeDialog } from '../fixtures/test-helpers';
import { mockData } from '../fixtures/mock-data';

test.describe('My Feature', () => {
  test.beforeEach(async ({ page }) => {
    // Setup before each test
    await page.goto('http://localhost:3000');
    await dismissWelcomeDialog(page);
  });
  
  test('should do something specific', async ({ page }) => {
    // Arrange: Set up preconditions
    const input = page.locator('input[placeholder="Enter idea"]');
    
    // Act: Perform user action
    await input.fill('My story idea');
    await page.locator('button:has-text("Generate")').click();
    
    // Assert: Verify outcome
    await expect(page.locator('h2')).toContainText('Story Generated');
  });
  
  test.skip('pending test explanation', async ({ page }) => {
    // Document why test is skipped
    // SKIP REASON: Waiting for XYZ to be implemented
    
    // Test code...
  });
});
\`\`\`

### Common Selectors
\`\`\`typescript
// By role (preferred)
page.locator('button:has-text("Generate")')
page.locator('input[placeholder="Enter..."]')

// By data-testid (if available)
page.locator('[data-testid="scene-card"]')

// By CSS class
page.locator('.story-form')
page.locator('.timeline-editor')

// By aria-label
page.locator('[aria-label="Close modal"]')
\`\`\`

## Debugging

### View Test in Browser
\`\`\`bash
npx playwright test --headed  # Keep browser open
\`\`\`

### Debug Single Test
\`\`\`bash
npx playwright test [filename] --debug
\`\`\`

### Take Screenshots
\`\`\`typescript
await page.screenshot({ path: 'screenshot.png' });
\`\`\`

### Inspect Element
DevTools will open automatically when using --debug mode. Use it to:
- Inspect element selectors
- Check computed styles
- Monitor network requests
- View console messages

## Known Limitations

### CORS (Phase 2 - 2 tests skipped)
Browser fetch to LM Studio blocked by missing CORS headers. Workaround: Skip or use Node fetch (server-side).

### UI Selectors (Phase 3 - 6 tests skipped)
Some selectors need verification against actual rendered DOM. Solution: Inspect with `npm run dev`, update selectors.

### ImportExport Timeout (Phase 5 - 1 test skipped)
IndexedDB import/export occasionally times out. Workaround: Reduce test data size or increase timeout.

## Best Practices

1. **One test, one feature**: Each test validates a single behavior
2. **Descriptive names**: Use clear test names explaining what's tested
3. **Use test.skip() with reasons**: Document why tests are skipped
4. **Prefer waitFor() over setTimeout()**: Avoid flaky timing issues
5. **Arrange, Act, Assert**: Structure tests clearly
6. **Reuse fixtures**: Use mock-data.ts and test-helpers.ts
7. **Document selectors**: Add comments explaining why specific selectors chosen

## Future Improvements

- [ ] Full E2E pipeline test (story â†’ keyframes â†’ videos)
- [ ] Telemetry validation tests
- [ ] Retry logic testing
- [ ] Performance benchmarking
- [ ] Visual regression testing
- [ ] Accessibility testing (a11y)

## Support

For questions about:
- **Test structure**: See test files for examples
- **Configuration**: Check playwright.config.ts and .env.local
- **Utilities**: Review test-helpers.ts and mock-data.ts
- **Selector issues**: Inspect DOM with DevTools
```

**INSTRUCTION 4.5: Validation**

1. Verify all .md files are updated:
   - Check README.md has React testing section
   - Check .github/copilot-instructions.md updated with testing approach
   - Check WORKFLOW_ARCHITECTURE_REFERENCE.md uses WAN workflow names
   - Check new REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md exists

2. Check for broken references:
   ```powershell
   grep -r "PipelineContext\|VisualBiblePanel" c:\Dev\gemDirect1\*.md | Select-String -Pattern "\.md:"
   ```
   (Should return no matches, or only archival docs)

3. Verify consistency:
   - All workflow references match (wan-t2i, wan-i2v)
   - All environment variable names consistent (VITE_LOCAL_*)
   - All file paths correct (absolute, not relative)

---

### PHASE 5: OPTIONAL ENHANCEMENTS (If Time Permits)

**Goal**: Improve test coverage beyond minimum.

**INSTRUCTION 5.1: Investigate CORS (45-60 minutes)**

**Decision**: Should we fix CORS or leave as known limitation?

**Research Task**:
1. Check LM Studio documentation for CORS configuration
2. Search for "LM Studio CORS" or "LM Studio headers"
3. Determine if configuration possible via CLI flags

**Option A**: Configure LM Studio CORS
- Update LM Studio startup command to add CORS headers
- Re-run Phase 2 tests (enable 2 skipped tests)
- Document fix in README.md

**Option B**: Add Reverse Proxy
- Create simple Express proxy to add CORS headers
- Document proxy setup

**Option C**: Keep as Known Limitation (Recommended if time short)
- Document as known limitation
- Skip this enhancement

**Decision**: Ask user which option to pursue.

**INSTRUCTION 5.2: Extend Phase 4 Tests (120-180 minutes)**

**If time permits**, implement full E2E pipeline test:

```typescript
test('complete story-to-video pipeline', async ({ page }) => {
  // 1. Generate story
  // 2. Break into scenes
  // 3. Generate keyframes
  // 4. Generate videos
  // 5. Verify artifacts
});
```

See `COMPREHENSIVE_AGENT_HANDOFF_NEXTPHASE.md` for detailed guidance on this enhancement.

---

### PHASE 6: FINAL VALIDATION (20-30 minutes)

**Goal**: Ensure everything works and is production-ready.

**INSTRUCTION 6.1: Run Full Test Suite**

```powershell
cd c:\Dev\gemDirect1
npx playwright test tests/e2e/ --reporter=list
```

**Record**:
- Total tests
- Passing count
- Failing count
- Skipped count
- Execution time

**Acceptance Criteria**:
- âœ… â‰¥27/40 tests passing (67.5%)
- âœ… All Phase 1, 4, 6 at 80%+ passing
- âœ… Known skips documented

**INSTRUCTION 6.2: Build Check**

```powershell
npm run build
```

**Check**:
- âœ… Build succeeds
- âœ… No TypeScript errors
- âœ… Output in dist/ folder
- âœ… No console warnings about missing files

**INSTRUCTION 6.3: Documentation Audit**

Spot-check 5 random .md files:
1. Check for broken links (search for [*.md])
2. Check for consistent terminology (WAN vs SVD, phases, etc.)
3. Check for correct file paths (absolute, not relative)
4. Check for dead code references

**INSTRUCTION 6.4: Final Status Report**

Create a completion report:

```
# AGENT COMPLETION REPORT

## Summary
Session XX of gemDirect1 development complete.

## Tasks Completed
- [x] Read all documentation
- [x] Fixed Phase 3 UI selectors
- [x] Updated README.md
- [x] Updated .github/copilot-instructions.md
- [x] Updated WORKFLOW_ARCHITECTURE_REFERENCE.md
- [x] Created REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md
- [ ] [Optional] Investigated CORS
- [ ] [Optional] Extended Phase 4 tests

## Final Metrics
- Tests: XX/40 passing (XX%)
- Phase 1: X/4 passing
- Phase 2: X/5 passing (CORS limitations)
- Phase 3: X/8 passing (UI verification)
- Phase 4: X/5 passing
- Phase 5: X/7 passing
- Phase 6: X/8 passing

## Files Modified
- tests/e2e/scene-generation.spec.ts
- tests/e2e/timeline-editing.spec.ts
- README.md
- .github/copilot-instructions.md
- WORKFLOW_ARCHITECTURE_REFERENCE.md
- [NEW] REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md

## Known Limitations
- Phase 2: CORS blocks browser fetch (documented workaround)
- Phase 3: Some selectors may need refinement per DOM structure
- Phase 4: Settings modal validation pending (1 test skipped)

## Production Readiness
âœ… Code builds successfully
âœ… Tests execute without errors
âœ… Documentation complete and consistent
âœ… No broken file references
âœ… All meta-documents updated

## Recommendations
1. [Next Priority] Implement full E2E pipeline test
2. [Enhancement] Fix CORS configuration for Phase 2
3. [Polish] Add visual regression testing
4. [Performance] Add test execution benchmarking

## Time Spent
- Reading & Planning: XX min
- Fixing UI Selectors: XX min
- Updating Documentation: XX min
- Optional Tasks: XX min
- Final Validation: XX min
- **Total**: XX hours

---

**Report by**: Agent [ID]
**Date**: [Date]
**Status**: âœ… COMPLETE - Ready for handoff
```

---

## SUCCESS CRITERIA

Your work is complete when:

âœ… **Test Coverage**:
- At least 27/40 tests passing (67.5%)
- Phase 3 tests moved from skipped to passing/failing
- All skipped tests have documented reasons

âœ… **Documentation**:
- README.md updated with React testing section
- .github/copilot-instructions.md updated with testing approach
- WORKFLOW_ARCHITECTURE_REFERENCE.md uses consistent WAN references
- REACT_BROWSER_TESTING_DEVELOPER_GUIDE.md created

âœ… **Code Quality**:
- npm run build completes with no errors
- npx playwright test runs without crashes
- No broken file references in any .md
- Consistent terminology throughout (WAN, phases, environment variables)

âœ… **Handoff**:
- Clear completion report submitted
- All decisions documented
- Known limitations clearly marked
- Recommendations for next work provided

---

## QUESTIONS YOU MIGHT HAVE

### "What if I can't fix a test?"
- Document the reason clearly
- Add `test.skip()` with explanation
- Move on to next task
- Report findings in completion report

### "What if I find a bug in the code?"
- Document it with clear reproduction steps
- Add to "known issues" section in your report
- Don't try to fix if it's outside scope
- Ask user for guidance if critical

### "What if a command fails?"
- Check error message carefully
- Try running it manually first
- Verify prerequisites (npm install, dev server running)
- Document error and ask user for help if blocked

### "Should I implement the optional tasks?"
- If you have <2 hours left: Skip optional tasks
- If you have 2-4 hours: Implement 1-2 optional tasks
- If you have >4 hours: Implement multiple optional tasks
- Always ask user if unsure

### "How detailed should documentation be?"
- Assume next developer has similar skills to you
- Include examples for non-obvious patterns
- Link to related code/tests
- Explain WHY, not just WHAT

---

## NOW BEGIN

You have all the information you need. Follow the phases in order:

1. **PHASE 1** (40 min): Read docs, understand context, create plan
2. **PHASE 2** (30 min): Get baseline test results
3. **PHASE 3** (30-45 min): Fix Phase 3 UI selectors
4. **PHASE 4** (60-90 min): Update meta-documents
5. **PHASE 5** (optional): Investigate CORS or extend tests
6. **PHASE 6** (20-30 min): Final validation

**Total time**: 4-8 hours depending on optional tasks

**Report progress** as you complete each phase.

**Submit completion report** when finished.

Good luck! ðŸš€

---

**Handoff Document Version**: 1.0  
**Created**: November 19, 2025  
**For**: Next AI Coding Agent Session
