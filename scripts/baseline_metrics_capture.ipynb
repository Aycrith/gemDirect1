{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df69ef67",
   "metadata": {},
   "source": [
    "# Prompt Optimization Baseline Metrics Capture\n",
    "\n",
    "**Purpose**: Systematically capture baseline metrics before implementing prompt optimization changes.\n",
    "\n",
    "**Created**: 2025-11-27  \n",
    "**Status**: Pre-Implementation Baseline Capture\n",
    "\n",
    "## Goals\n",
    "1. Capture 10-20 keyframe prompt generations with current defaults\n",
    "2. Log prompt length, token estimates, CLIP chunk counts\n",
    "3. Audit feature flags for plan-to-repo drift\n",
    "4. Validate negative prompt coverage and deduplication\n",
    "5. Generate test scaffolds for missing test files\n",
    "\n",
    "## Current Feature Flag Defaults (from `utils/featureFlags.ts`)\n",
    "- `subjectFirstPrompts`: `false`\n",
    "- `promptQualityGate`: `false`  \n",
    "- `promptTokenGuard`: `'warn'` (NOT 'off' as handoff implies)\n",
    "- `keyframePromptPipeline`: `true`\n",
    "- `enhancedNegativePrompts`: `false`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a552a",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9757d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(r\"c:\\Dev\\gemDirect1\")\n",
    "SERVICES_DIR = PROJECT_ROOT / \"services\"\n",
    "UTILS_DIR = PROJECT_ROOT / \"utils\"\n",
    "\n",
    "# Key files to analyze\n",
    "FILES = {\n",
    "    \"featureFlags\": UTILS_DIR / \"featureFlags.ts\",\n",
    "    \"promptConstants\": SERVICES_DIR / \"promptConstants.ts\",\n",
    "    \"promptPipeline\": SERVICES_DIR / \"promptPipeline.ts\",\n",
    "    \"promptWeighting\": SERVICES_DIR / \"promptWeighting.ts\",\n",
    "    \"tokenValidator\": SERVICES_DIR / \"tokenValidator.ts\",\n",
    "    \"generationMetrics\": SERVICES_DIR / \"generationMetrics.ts\",\n",
    "    \"handoff\": PROJECT_ROOT / \"AGENT_HANDOFF_PROMPT_OPTIMIZATION_IMPLEMENTATION_20251127.md\",\n",
    "    \"improvementPlan\": PROJECT_ROOT / \"Documentation\" / \"PROMPT_OPTIMIZATION_IMPROVEMENT_PLAN.md\",\n",
    "}\n",
    "\n",
    "# Verify all files exist\n",
    "for name, path in FILES.items():\n",
    "    status = \"‚úÖ\" if path.exists() else \"‚ùå\"\n",
    "    print(f\"{status} {name}: {path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7bf82",
   "metadata": {},
   "source": [
    "## Section 2: Analyze Feature Flag Configuration\n",
    "\n",
    "Parse `utils/featureFlags.ts` to extract current defaults and compare against documentation claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_flag_defaults(content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract DEFAULT_FEATURE_FLAGS values from featureFlags.ts\"\"\"\n",
    "    defaults = {}\n",
    "    \n",
    "    # Find the DEFAULT_FEATURE_FLAGS block\n",
    "    match = re.search(r'export const DEFAULT_FEATURE_FLAGS.*?=\\s*\\{([^}]+(?:\\{[^}]*\\}[^}]*)*)\\}', content, re.DOTALL)\n",
    "    if not match:\n",
    "        return defaults\n",
    "    \n",
    "    block = match.group(1)\n",
    "    \n",
    "    # Parse each flag: value line\n",
    "    for line in block.split('\\n'):\n",
    "        line = line.strip()\n",
    "        # Match patterns like: flagName: true, flagName: false, flagName: 'value'\n",
    "        flag_match = re.match(r\"(\\w+):\\s*(true|false|'[^']+'),?\\s*(?://.*)?$\", line)\n",
    "        if flag_match:\n",
    "            name = flag_match.group(1)\n",
    "            value_str = flag_match.group(2)\n",
    "            # Convert to Python types\n",
    "            if value_str == 'true':\n",
    "                value = True\n",
    "            elif value_str == 'false':\n",
    "                value = False\n",
    "            else:\n",
    "                value = value_str.strip(\"'\")\n",
    "            defaults[name] = value\n",
    "    \n",
    "    return defaults\n",
    "\n",
    "# Extract actual defaults\n",
    "content = FILES[\"featureFlags\"].read_text(encoding='utf-8')\n",
    "actual_defaults = extract_feature_flag_defaults(content)\n",
    "\n",
    "# Key flags for prompt optimization\n",
    "key_flags = [\n",
    "    'subjectFirstPrompts',\n",
    "    'promptQualityGate', \n",
    "    'promptTokenGuard',\n",
    "    'keyframePromptPipeline',\n",
    "    'enhancedNegativePrompts',\n",
    "    'promptWeighting',\n",
    "    'qualityPrefixVariant',\n",
    "    'bibleV2SaveSync',\n",
    "    'sceneListValidationMode',\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE FLAG DEFAULTS (Actual vs Handoff Claims)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Handoff claims (from document analysis)\n",
    "handoff_claims = {\n",
    "    'subjectFirstPrompts': False,  # Correct in handoff\n",
    "    'promptQualityGate': False,    # Correct in handoff\n",
    "    'promptTokenGuard': 'off',     # WRONG - handoff says 'off', actual is 'warn'\n",
    "    'keyframePromptPipeline': True, # Correct (but handoff doesn't mention)\n",
    "    'enhancedNegativePrompts': False,\n",
    "}\n",
    "\n",
    "for flag in key_flags:\n",
    "    actual = actual_defaults.get(flag, 'NOT FOUND')\n",
    "    claimed = handoff_claims.get(flag, 'not specified')\n",
    "    match = \"‚úÖ\" if actual == claimed else \"‚ö†Ô∏è DRIFT\"\n",
    "    print(f\"{match} {flag}: actual={actual}, claimed={claimed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8e852",
   "metadata": {},
   "source": [
    "## Section 3: Audit Negative Prompt Coverage\n",
    "\n",
    "Extract `ENHANCED_NEGATIVE_SET` categories and identify missing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_negative_categories(content: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Extract ENHANCED_NEGATIVE_SET categories from promptConstants.ts\"\"\"\n",
    "    categories = {}\n",
    "    \n",
    "    # Find the ENHANCED_NEGATIVE_SET block\n",
    "    match = re.search(r'export const ENHANCED_NEGATIVE_SET\\s*=\\s*\\{([^}]+(?:\\[[^\\]]*\\][^}]*)*)\\}', content, re.DOTALL)\n",
    "    if not match:\n",
    "        return categories\n",
    "    \n",
    "    block = match.group(1)\n",
    "    \n",
    "    # Parse each category\n",
    "    cat_pattern = r\"(\\w+):\\s*\\[((?:[^[\\]]*|\\[[^\\]]*\\])*)\\]\"\n",
    "    for cat_match in re.finditer(cat_pattern, block, re.DOTALL):\n",
    "        cat_name = cat_match.group(1)\n",
    "        terms_block = cat_match.group(2)\n",
    "        # Extract quoted strings\n",
    "        terms = re.findall(r\"'([^']+)'\", terms_block)\n",
    "        categories[cat_name] = terms\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# Extract current categories\n",
    "content = FILES[\"promptConstants\"].read_text(encoding='utf-8')\n",
    "current_categories = extract_negative_categories(content)\n",
    "\n",
    "# Required categories per plan\n",
    "required_categories = {\n",
    "    'quality': ['lowres', 'worst quality', 'bad quality', 'low quality', 'blurry'],  # Sample\n",
    "    'anatomy': ['bad anatomy', 'deformed', 'disfigured'],  # Sample\n",
    "    'composition': ['cropped', 'cut off', 'out of frame'],  # Sample\n",
    "    'text_artifacts': ['text', 'watermark', 'logo', 'signature', 'username', 'copyright', 'caption', 'subtitle', 'credits', 'stock photo'],\n",
    "    'depth': ['flat composition', 'no depth', 'incorrect perspective', 'fisheye distortion', 'lens distortion', 'flat lighting'],\n",
    "    'motion': ['static pose', 'frozen movement', 'motion blur artifacts', 'ghosting', 'stuttering', 'temporal inconsistency', 'flickering'],\n",
    "    'style_contamination': ['cartoon', 'anime', 'illustration', 'sketch', 'drawing', 'painting', 'abstract', 'surreal', 'CGI'],\n",
    "    'quality_tiers': ['worst quality', 'low quality', 'normal quality', 'jpeg artifacts', 'compression artifacts', 'pixelated', 'noise', 'banding'],\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENHANCED_NEGATIVE_SET CATEGORY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cat_name in required_categories:\n",
    "    if cat_name in current_categories:\n",
    "        count = len(current_categories[cat_name])\n",
    "        print(f\"‚úÖ {cat_name}: {count} terms\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISSING: {cat_name}\")\n",
    "\n",
    "print(f\"\\nCurrent categories: {len(current_categories)}\")\n",
    "print(f\"Required categories: {len(required_categories)}\")\n",
    "print(f\"Missing: {len(required_categories) - len(current_categories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb117f",
   "metadata": {},
   "source": [
    "## Section 4: Validate Prompt Weighting Presets\n",
    "\n",
    "Analyze `services/promptWeighting.ts` for existing presets and identify missing `balanced` preset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weighting_presets(content: str) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Extract WEIGHTING_PRESETS from promptWeighting.ts\"\"\"\n",
    "    presets = {}\n",
    "    \n",
    "    # Find the WEIGHTING_PRESETS block\n",
    "    match = re.search(r'export const WEIGHTING_PRESETS\\s*=\\s*\\{([^}]+(?:\\{[^}]*\\}[^}]*)*)\\}', content, re.DOTALL)\n",
    "    if not match:\n",
    "        return presets\n",
    "    \n",
    "    block = match.group(1)\n",
    "    \n",
    "    # Parse each preset\n",
    "    preset_pattern = r\"(\\w+):\\s*\\{([^}]+)\\}\"\n",
    "    for preset_match in re.finditer(preset_pattern, block):\n",
    "        preset_name = preset_match.group(1)\n",
    "        weights_block = preset_match.group(2)\n",
    "        \n",
    "        weights = {}\n",
    "        for line in weights_block.split('\\n'):\n",
    "            weight_match = re.match(r\"\\s*(\\w+):\\s*([\\d.]+)\", line)\n",
    "            if weight_match:\n",
    "                weights[weight_match.group(1)] = float(weight_match.group(2))\n",
    "        \n",
    "        if weights:\n",
    "            presets[preset_name] = weights\n",
    "    \n",
    "    return presets\n",
    "\n",
    "# Extract current presets\n",
    "content = FILES[\"promptWeighting\"].read_text(encoding='utf-8')\n",
    "current_presets = extract_weighting_presets(content)\n",
    "\n",
    "# Required presets per plan\n",
    "required_presets = {\n",
    "    'subjectEmphasis': {'summary': 1.2, 'characters': 1.1, 'subject': 1.3, 'character': 1.2, 'style': 1.0, 'background': 0.8},\n",
    "    'styleEmphasis': {'style': 1.1, 'technical': 1.05, 'subject': 1.0, 'character': 1.0, 'background': 0.9},\n",
    "    'balanced': {'subject': 1.0, 'character': 1.0, 'style': 1.0, 'background': 1.0},  # MISSING\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"WEIGHTING_PRESETS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for preset_name in required_presets:\n",
    "    if preset_name in current_presets:\n",
    "        weights = current_presets[preset_name]\n",
    "        print(f\"‚úÖ {preset_name}: {weights}\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISSING: {preset_name}\")\n",
    "\n",
    "# Check for background weights (needed for V2)\n",
    "has_background = any('background' in preset for preset in current_presets.values())\n",
    "print(f\"\\n‚ö†Ô∏è Background weights present: {has_background}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58104ec2",
   "metadata": {},
   "source": [
    "## Section 5: Type Contract Validation\n",
    "\n",
    "Check `AssembledPrompt` interface alignment with `assemblePromptForProvider` return type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interface_properties(content: str, interface_name: str) -> List[str]:\n",
    "    \"\"\"Extract property names from a TypeScript interface\"\"\"\n",
    "    properties = []\n",
    "    \n",
    "    pattern = rf'export interface {interface_name}\\s*\\{{([^}}]+)\\}}'\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "    if not match:\n",
    "        return properties\n",
    "    \n",
    "    block = match.group(1)\n",
    "    \n",
    "    # Match property declarations\n",
    "    for line in block.split('\\n'):\n",
    "        prop_match = re.match(r'\\s+(\\w+)\\??:\\s*', line)\n",
    "        if prop_match:\n",
    "            properties.append(prop_match.group(1))\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def extract_function_return(content: str, func_name: str) -> List[str]:\n",
    "    \"\"\"Extract returned object properties from a function\"\"\"\n",
    "    properties = []\n",
    "    \n",
    "    # Find the return statement\n",
    "    pattern = rf'export function {func_name}[^{{]+\\{{.*?return\\s*\\{{([^}}]+)\\}}'\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "    if not match:\n",
    "        return properties\n",
    "    \n",
    "    block = match.group(1)\n",
    "    \n",
    "    # Match property assignments\n",
    "    for line in block.split('\\n'):\n",
    "        prop_match = re.match(r'\\s+(\\w+)[,:]', line)\n",
    "        if prop_match:\n",
    "            properties.append(prop_match.group(1))\n",
    "    \n",
    "    return properties\n",
    "\n",
    "# Analyze AssembledPrompt interface\n",
    "content = FILES[\"promptPipeline\"].read_text(encoding='utf-8')\n",
    "interface_props = extract_interface_properties(content, 'AssembledPrompt')\n",
    "return_props = extract_function_return(content, 'assemblePromptForProvider')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TYPE CONTRACT ANALYSIS: AssembledPrompt\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nInterface properties: {interface_props}\")\n",
    "print(f\"Function returns: {return_props}\")\n",
    "\n",
    "# Check for tokenWarning mismatch (known issue)\n",
    "has_token_warning_in_return = 'tokenWarning' in content.split('assemblePromptForProvider')[1].split('return')[1][:500]\n",
    "has_token_counts_in_interface = 'tokens' in interface_props\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è tokenWarning in return: likely present (check manually)\")\n",
    "print(f\"tokens in interface: {has_token_counts_in_interface}\")\n",
    "print(\"\\nüîß FIX NEEDED: Align return type with interface definition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7512bb0",
   "metadata": {},
   "source": [
    "## Section 6: Generate Baseline Metrics JSON\n",
    "\n",
    "Create a baseline configuration and sample prompt metrics for A/B comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1239730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token estimation heuristic (matches services/tokenValidator.ts)\n",
    "def estimate_tokens(text: str, provider: str = 'comfyui') -> int:\n",
    "    \"\"\"Estimate token count using provider-specific ratios\"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    ratios = {'clip': 3.5, 'comfyui': 3.5, 'gemini': 4.0, 'default': 4.0}\n",
    "    ratio = ratios.get(provider, ratios['default'])\n",
    "    return int(len(text) / ratio + 0.5)\n",
    "\n",
    "def estimate_clip_chunks(text: str) -> int:\n",
    "    \"\"\"Estimate CLIP 77-token chunks needed\"\"\"\n",
    "    tokens = estimate_tokens(text, 'comfyui')\n",
    "    return (tokens + 76) // 77  # Ceiling division\n",
    "\n",
    "# Sample prompts representing different scene types\n",
    "sample_prompts = [\n",
    "    # Short scene summary\n",
    "    \"A dark alley at night, neon signs reflecting on wet pavement, a lone figure walks away.\",\n",
    "    \n",
    "    # Medium complexity with characters\n",
    "    \"Elena, tall athletic woman with long dark hair and piercing green eyes, confronts Malachar in the ancient throne room. Dramatic shadows play across marble columns.\",\n",
    "    \n",
    "    # Complex with style direction\n",
    "    \"Wide establishing shot of the cyberpunk megacity skyline at dusk. Holographic advertisements pierce the smog. Flying vehicles streak between towering arcologies. Cinematic lighting, volumetric fog, 16:9 aspect ratio.\",\n",
    "    \n",
    "    # Character-heavy\n",
    "    \"Close-up on Elena's determined expression as she grips the enchanted blade. Malachar looms in the background, his glowing red eyes visible through the shadows. Golden hour lighting streams through shattered windows.\",\n",
    "    \n",
    "    # Action scene\n",
    "    \"Dynamic medium shot: Elena leaps across the crumbling bridge as explosions tear through the ancient structure. Motion blur on debris, sharp focus on protagonist, epic scale composition.\",\n",
    "]\n",
    "\n",
    "# Generate baseline metrics\n",
    "baseline_data = {\n",
    "    \"captureDate\": datetime.now().isoformat(),\n",
    "    \"featureFlagsUsed\": {\n",
    "        \"subjectFirstPrompts\": False,\n",
    "        \"promptQualityGate\": False,\n",
    "        \"promptTokenGuard\": \"warn\",\n",
    "        \"keyframePromptPipeline\": True,\n",
    "        \"enhancedNegativePrompts\": False,\n",
    "    },\n",
    "    \"prompts\": []\n",
    "}\n",
    "\n",
    "for i, prompt in enumerate(sample_prompts, 1):\n",
    "    token_count = estimate_tokens(prompt)\n",
    "    clip_chunks = estimate_clip_chunks(prompt)\n",
    "    \n",
    "    metrics = {\n",
    "        \"id\": f\"baseline-{i:03d}\",\n",
    "        \"prompt\": prompt,\n",
    "        \"charCount\": len(prompt),\n",
    "        \"tokenEstimate\": token_count,\n",
    "        \"clipChunks\": clip_chunks,\n",
    "        \"subjectPosition\": prompt.find(','),  # First comma marks subject end\n",
    "        \"withinBudget\": token_count <= 600,  # sceneKeyframe budget\n",
    "    }\n",
    "    baseline_data[\"prompts\"].append(metrics)\n",
    "    \n",
    "    print(f\"Prompt {i}: {token_count} tokens, {clip_chunks} CLIP chunks, budget: {'‚úÖ' if metrics['withinBudget'] else '‚ùå'}\")\n",
    "\n",
    "# Save baseline\n",
    "baseline_path = PROJECT_ROOT / \"scripts\" / \"baseline_metrics.json\"\n",
    "with open(baseline_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(baseline_data, f, indent=2)\n",
    "    \n",
    "print(f\"\\n‚úÖ Saved baseline to: {baseline_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da230d",
   "metadata": {},
   "source": [
    "## Section 7: Generate Test Scaffold Templates\n",
    "\n",
    "Create stub test files for missing test coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e095861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scaffold templates\n",
    "test_scaffolds = {\n",
    "    \"promptWeighting.test.ts\": '''/**\n",
    " * Tests for promptWeighting service\n",
    " * Validates weighting syntax generation, parsing, and preset application\n",
    " */\n",
    "import { describe, it, expect } from 'vitest';\n",
    "import { \n",
    "    applyWeight, \n",
    "    parseWeightedTerms, \n",
    "    WEIGHTING_PRESETS,\n",
    "    WEIGHT_MIN,\n",
    "    WEIGHT_MAX,\n",
    "} from '../promptWeighting';\n",
    "\n",
    "describe('promptWeighting', () => {\n",
    "    describe('applyWeight', () => {\n",
    "        it('should return unweighted term when weight is 1.0', () => {\n",
    "            expect(applyWeight('subject', 1)).toBe('subject');\n",
    "            expect(applyWeight('subject', 1.0)).toBe('subject');\n",
    "        });\n",
    "\n",
    "        it('should apply weighting syntax for non-1.0 weights', () => {\n",
    "            expect(applyWeight('subject', 1.2)).toBe('(subject:1.20)');\n",
    "            expect(applyWeight('subject', 0.8)).toBe('(subject:0.80)');\n",
    "        });\n",
    "\n",
    "        it('should clamp weights to safe range [0.1, 2.0]', () => {\n",
    "            expect(applyWeight('term', 0.05)).toBe('(term:0.10)');\n",
    "            expect(applyWeight('term', 3.0)).toBe('(term:2.00)');\n",
    "        });\n",
    "\n",
    "        it('should handle empty strings', () => {\n",
    "            expect(applyWeight('', 1.2)).toBe('');\n",
    "            expect(applyWeight('  ', 1.2)).toBe('  ');\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('parseWeightedTerms', () => {\n",
    "        it('should extract weighted terms from prompt', () => {\n",
    "            const result = parseWeightedTerms('(subject:1.20), style, (background:0.80)');\n",
    "            expect(result).toHaveLength(2);\n",
    "            expect(result[0]).toEqual({ term: 'subject', weight: 1.20 });\n",
    "            expect(result[1]).toEqual({ term: 'background', weight: 0.80 });\n",
    "        });\n",
    "\n",
    "        it('should return empty array for prompts without weights', () => {\n",
    "            expect(parseWeightedTerms('subject, style, background')).toEqual([]);\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('WEIGHTING_PRESETS', () => {\n",
    "        it('should have subjectEmphasis preset', () => {\n",
    "            expect(WEIGHTING_PRESETS.subjectEmphasis).toBeDefined();\n",
    "            expect(WEIGHTING_PRESETS.subjectEmphasis.summary).toBeGreaterThan(1);\n",
    "        });\n",
    "\n",
    "        it('should have styleEmphasis preset', () => {\n",
    "            expect(WEIGHTING_PRESETS.styleEmphasis).toBeDefined();\n",
    "            expect(WEIGHTING_PRESETS.styleEmphasis.style).toBeGreaterThan(1);\n",
    "        });\n",
    "\n",
    "        // TODO: Add balanced preset\n",
    "        it.skip('should have balanced preset with all weights = 1.0', () => {\n",
    "            expect(WEIGHTING_PRESETS.balanced).toBeDefined();\n",
    "            expect(WEIGHTING_PRESETS.balanced.subject).toBe(1.0);\n",
    "        });\n",
    "    });\n",
    "});\n",
    "''',\n",
    "\n",
    "    \"styleExtractor.test.ts\": '''/**\n",
    " * Tests for styleExtractor service (STUB)\n",
    " * Validates style keyword extraction from director\\'s vision\n",
    " */\n",
    "import { describe, it, expect } from 'vitest';\n",
    "\n",
    "// TODO: Import from '../styleExtractor' when service is created\n",
    "\n",
    "describe('styleExtractor', () => {\n",
    "    describe('extractStyleKeywords', () => {\n",
    "        it.todo('should extract lighting keywords from vision text');\n",
    "        it.todo('should extract camera angle keywords');\n",
    "        it.todo('should extract mood/atmosphere keywords');\n",
    "        it.todo('should prioritize categories: lighting > mood > film > camera');\n",
    "        it.todo('should limit to maxTerms parameter');\n",
    "    });\n",
    "\n",
    "    describe('formatStylesForPrompt', () => {\n",
    "        it.todo('should format styles with weighting when enabled');\n",
    "        it.todo('should format styles without weighting when disabled');\n",
    "        it.todo('should handle empty style array');\n",
    "    });\n",
    "});\n",
    "''',\n",
    "\n",
    "    \"characterTracker.test.ts\": '''/**\n",
    " * Tests for characterTracker service (STUB)\n",
    " * Validates character appearance tracking and continuity analysis\n",
    " */\n",
    "import { describe, it, expect } from 'vitest';\n",
    "\n",
    "// TODO: Import from '../characterTracker' when service is created\n",
    "\n",
    "describe('characterTracker', () => {\n",
    "    describe('trackCharacterAppearances', () => {\n",
    "        it.todo('should track character mentions across timeline shots');\n",
    "        it.todo('should identify explicit vs implicit character references');\n",
    "        it.todo('should link appearances to character profiles');\n",
    "    });\n",
    "\n",
    "    describe('analyzeCharacterContinuity', () => {\n",
    "        it.todo('should warn when protagonist absent > 3 consecutive shots');\n",
    "        it.todo('should warn when supporting character absent > 5 shots');\n",
    "        it.todo('should not warn for normal appearance gaps');\n",
    "        it.todo('should detect sudden character appearances');\n",
    "    });\n",
    "\n",
    "    describe('MAX_GAP constants', () => {\n",
    "        it.todo('should define MAX_PROTAGONIST_GAP = 3');\n",
    "        it.todo('should define MAX_SUPPORTING_GAP = 5');\n",
    "    });\n",
    "});\n",
    "''',\n",
    "\n",
    "    \"generationMetrics.test.ts\": '''/**\n",
    " * Tests for generationMetrics service\n",
    " * Validates A/B testing metrics collection and Bayesian analysis\n",
    " */\n",
    "import { describe, it, expect } from 'vitest';\n",
    "import {\n",
    "    createMetrics,\n",
    "    generateMetricId,\n",
    "    summarizeMetricsByVariant,\n",
    "    isSignificantDifference,\n",
    "    MIN_SAMPLE_SIZE,\n",
    "} from '../generationMetrics';\n",
    "\n",
    "describe('generationMetrics', () => {\n",
    "    describe('generateMetricId', () => {\n",
    "        it('should generate unique IDs', () => {\n",
    "            const id1 = generateMetricId();\n",
    "            const id2 = generateMetricId();\n",
    "            expect(id1).not.toBe(id2);\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('createMetrics', () => {\n",
    "        it('should create metrics with required fields', () => {\n",
    "            const metrics = createMetrics({\n",
    "                promptVariantId: 'control',\n",
    "                provider: 'comfyui',\n",
    "            });\n",
    "            expect(metrics.promptVariantId).toBe('control');\n",
    "            expect(metrics.provider).toBe('comfyui');\n",
    "            expect(metrics.timestamp).toBeDefined();\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('summarizeMetricsByVariant', () => {\n",
    "        it('should aggregate metrics by variant ID', () => {\n",
    "            const metrics = [\n",
    "                createMetrics({ promptVariantId: 'control', provider: 'comfyui', success: true }),\n",
    "                createMetrics({ promptVariantId: 'control', provider: 'comfyui', success: false }),\n",
    "                createMetrics({ promptVariantId: 'optimized', provider: 'comfyui', success: true }),\n",
    "            ];\n",
    "            \n",
    "            const summaries = summarizeMetricsByVariant(metrics);\n",
    "            expect(summaries.get('control')?.sampleSize).toBe(2);\n",
    "            expect(summaries.get('optimized')?.sampleSize).toBe(1);\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('isSignificantDifference', () => {\n",
    "        it('should require minimum sample size', () => {\n",
    "            expect(isSignificantDifference(0.5, 0.6, 10, 10)).toBe(false);\n",
    "            expect(isSignificantDifference(0.5, 0.6, 30, 30)).toBe(true);\n",
    "        });\n",
    "    });\n",
    "\n",
    "    describe('Bayesian A/B testing', () => {\n",
    "        it.todo('should calculate P(treatment > control)');\n",
    "        it.todo('should converge with fewer samples than frequentist');\n",
    "    });\n",
    "});\n",
    "''',\n",
    "}\n",
    "\n",
    "# Check which test files exist\n",
    "tests_dir = SERVICES_DIR / \"__tests__\"\n",
    "print(\"=\"*60)\n",
    "print(\"TEST FILE STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for filename in test_scaffolds:\n",
    "    filepath = tests_dir / filename\n",
    "    if filepath.exists():\n",
    "        print(f\"‚úÖ EXISTS: {filename}\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISSING: {filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ Test directory: {tests_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd42c9",
   "metadata": {},
   "source": [
    "## Section 8: Documentation Drift Summary\n",
    "\n",
    "Generate a summary of discrepancies between handoff docs and actual codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate documentation drift report\n",
    "drift_report = {\n",
    "    \"generated\": datetime.now().isoformat(),\n",
    "    \"issues\": [\n",
    "        {\n",
    "            \"category\": \"Feature Flag Defaults\",\n",
    "            \"issue\": \"promptTokenGuard default\",\n",
    "            \"handoff_claims\": \"'off'\",\n",
    "            \"actual_value\": \"'warn'\",\n",
    "            \"severity\": \"HIGH\",\n",
    "            \"fix\": \"Update handoff to reflect actual 'warn' default; Phase 6 is single-step jump to 'block'\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Feature Flag Defaults\",\n",
    "            \"issue\": \"keyframePromptPipeline not documented\",\n",
    "            \"handoff_claims\": \"not mentioned\",\n",
    "            \"actual_value\": \"true\",\n",
    "            \"severity\": \"MEDIUM\",\n",
    "            \"fix\": \"Add keyframePromptPipeline=true to handoff infrastructure table\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Line Number References\",\n",
    "            \"issue\": \"Stale line numbers throughout\",\n",
    "            \"handoff_claims\": \"subjectFirstPrompts at line 78/189\",\n",
    "            \"actual_value\": \"~line 73\",\n",
    "            \"severity\": \"LOW\",\n",
    "            \"fix\": \"Remove all line numbers; instruct agents to use symbol search\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Negative Prompt Categories\",\n",
    "            \"issue\": \"5 categories missing from ENHANCED_NEGATIVE_SET\",\n",
    "            \"handoff_claims\": \"3/8 categories exist\",\n",
    "            \"actual_value\": \"3 exist: quality, anatomy, composition\",\n",
    "            \"severity\": \"HIGH\",\n",
    "            \"fix\": \"Add text_artifacts, depth, motion, style_contamination, quality_tiers\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Weighting Presets\",\n",
    "            \"issue\": \"balanced preset missing\",\n",
    "            \"handoff_claims\": \"3 presets mentioned\",\n",
    "            \"actual_value\": \"2 presets exist: subjectEmphasis, styleEmphasis\",\n",
    "            \"severity\": \"MEDIUM\",\n",
    "            \"fix\": \"Add balanced preset with all weights = 1.0; add background weight key\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Type Contract\",\n",
    "            \"issue\": \"AssembledPrompt interface mismatch\",\n",
    "            \"handoff_claims\": \"interface has tokens property\",\n",
    "            \"actual_value\": \"assemblePromptForProvider returns tokenWarning (string), not tokens object\",\n",
    "            \"severity\": \"HIGH\",\n",
    "            \"fix\": \"Align return type before adding new callers\"\n",
    "        },\n",
    "    ],\n",
    "    \"recommended_actions\": [\n",
    "        \"1. Update AGENT_HANDOFF_PROMPT_OPTIMIZATION_IMPLEMENTATION_20251127.md\",\n",
    "        \"2. Update Documentation/PROMPT_OPTIMIZATION_IMPROVEMENT_PLAN.md\",\n",
    "        \"3. Expand ENHANCED_NEGATIVE_SET with 5 missing categories\",\n",
    "        \"4. Add balanced preset to WEIGHTING_PRESETS\",\n",
    "        \"5. Fix AssembledPrompt type alignment\",\n",
    "        \"6. Create missing test scaffolds\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save drift report\n",
    "drift_path = PROJECT_ROOT / \"scripts\" / \"documentation_drift_report.json\"\n",
    "with open(drift_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(drift_report, f, indent=2)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DOCUMENTATION DRIFT REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for issue in drift_report[\"issues\"]:\n",
    "    severity_icon = {\"HIGH\": \"üî¥\", \"MEDIUM\": \"üü°\", \"LOW\": \"üü¢\"}[issue[\"severity\"]]\n",
    "    print(f\"\\n{severity_icon} [{issue['severity']}] {issue['category']}: {issue['issue']}\")\n",
    "    print(f\"   Claimed: {issue['handoff_claims']}\")\n",
    "    print(f\"   Actual:  {issue['actual_value']}\")\n",
    "    print(f\"   Fix:     {issue['fix']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Saved drift report to: {drift_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
